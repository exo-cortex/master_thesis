\section{todo things on the todo list.}

\subsection{reading list}
	todo:
	\begin{itemize}
		\item \cite{ZOU09b} splay states in a ring of coupled oscillators: from local to global coupling.
		\item \cite{YAN11, POP11, KLI17, PAD13, LUE13b} - von Yanchuk empfohlen. delay-reduzierung. usw.
		\item \cite{YAN09} periodische lÃ¶sungen
	\end{itemize}
	
	done:
	\begin{itemize}
		\item \cite{EAR03, CHO09, YEU99} synchrony in delay coupled networks
	\end{itemize}
	

\subsection{programming work}

\subsection{research work}
\begin{itemize}
    \item check different weights
    \item check symmetry breaking nodes
    \item check "standard" topologies
    \item check breaking of standard topologies (extra links)
\end{itemize}

\subsection{graphics/plots}
\begin{itemize}
	\item stuart landau oscillator: complex plane, driven by input, with delayed feedback
	\item linear memory recall curve
    \item feed in plus system response for different ratios of theta and lambda
    \item rN from 1 to 32, rN from 1 to 32 with plot.
    \item generalized order parameter -> impact of extra edge to generalized order parameter
    
\end{itemize}

here comes the intro and all the important references...
small world \cite{WAT98}.

\subsection{theory}
	\begin{itemize}
		\item reservoir computing. definitions RC with delay, cc, masks, virtual nodes (more later)
		\item virtual networks through multiplexing. breakdown of analogy (random masks)
		\item tasks, training, covariance
		\item linear memory, legendre polynomials, narma
		\item linear regression. result: weights (plot weights for linear memories).
		\item networks
	\end{itemize}

\subsection{results}
	\begin{itemize}
		\item increasing network size
		\item increasing virtualization
		\item increasing input strength
	\end{itemize}

\subsection{further investigations/open question}
	interesting subjects that were not investigated in this work
	\begin{itemize}
		\item the flow of information within the network by omitting the readout from different nodes
		\item designing tasks where two seperate data streams are being fed to different nodes in the network.
		\item can a network perform two calculations on different streams of data? (aka quantify multitasking/crosstalk).
	\end{itemize}

by feeding information from different timeseries to different nodes within the same network the flow of information might be investigated. Also the mixing of those two streams of data. From two distributions $u_1$ and $u_2$ the tasks $O(u_1,u_2)$ can be derived. By omitting the readout of singular nodes the impact of them to the computation capacities might be investigated. This can be used in order to "chase" the importance of certain Nodes for different tasks.



For a system trying to recall the values from a distribution $u_1$ the totally uncorrelated inputs from $u_2$ somewhere else in the system will act like noise. 
